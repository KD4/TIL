HyperLogLog
===========================================

대용량 데이터셋에서 유니크한 값, 즉 카디널리티를 어떻게 구할 것인가? 에 대한 문제를 Cardinality Estimation Problem 또는 Count-distinct problem 이라고 한다.

적당한 데이터셋은 Set 자료 구조를 이용해서 구할 수 있지만 수백만, 수천만 이상의 데이터를 Set에 저장하면 공간, 시간 자원의 비용이 크게 증가하게 된다. 

이를 해결하기 위한 알고리즘이 바로 HyperLogLog로, 어느정도 오차(1~2%)를 허용하면서 유니크 카운트 수를 구할 수 잇는 자료 구조이다.

loglog > superLogLog > HyperLogLog 라는 형태로 발전해왔다. 

HyperLogLog는 매우 적은 메모리로 많은 데이터가 들어가 있는 집합의 원소 개수를 정확하지 않지만 최대한 정확하게 계산해주는 알고리즘으로 

알고리즘의 핵심 아이디어는 데이터를 해싱하고 해싱값의 일부를 취해서 비트 배열에 저장하는 것이다.

Redis에서는 HyperLogLog를 지원하고 있어서 MAU 측정 등 유니크 카운팅을 구하려는 요구사항에 쉽게 대응할 수 있는다.