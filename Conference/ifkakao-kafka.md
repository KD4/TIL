ifKakao - 카프카, 산전수전 노하우
=================================

발표자 : 고승범(peter.ko) - 카카오

설명: 카카오에서는 빅데이터 분석, 처리부터 모든 개발 플랫폼을 이어주는 솔루션으로 급부상한 카프카(kafka)를 전사 공용 서비스로 운영하고 있습니다. 전사 공용 카프카를 직접 운영하면서 경험한 트러블슈팅과 운영 노하우 등을 공유하고자 합니다. 특히 카프카를 처음 접하시는 분들이나 이미 사용 중이신 분들이 많이 궁금해하는 프로듀서와 컨슈머 사용 시의 주의점 등에 대해서도 설명합니다.

발표 속기
---------------------------------

## 카프카 용어 정리
- 프로듀서: 카프카로 메시지를 보내는 역할
- 카프카: 프로듀서의 메시지를 저장하는 역할
- 컨슈머: 카프카의 메시지를 가져오는 역할
- 주키퍼: 분산 코디네이션 시스템, 메타데이터 관리, 클러스터 노드 관리를 담당

카프카 클러스터를 처음 구성한다면, 주키퍼 리플리케이션 과반수 쿼럼(정족수) 방식이기때문에 홀수를 유지해야한다.

카프카 브로커는 리플리케이션 방식이 쿼럼 방식이 아니기때문에 브로커 수 제한은 없지만 최소 3이상을 권장한다.

사용량이 많으면 주키퍼는 그대로 두고 브로커만 추가해서 스케일 아웃 할 수 있다.

## 카카오의 카프카 사용 현황
- 전사 공용 카프카를 사용함.
- 7개 클러스터 130개 서버를 운영
- IDC 2곳에 분산 운영
- 각 IDC 마다 주키퍼를 따로 두어 운영
- 하루 260억 / 초당 300만 건 메시징 처리
- 전사 카프카로 들어오는 데이터 사이즈, in = 240TB / out = 370TB
- 카프카 같은 경우 하나의 토픽을 주제로 프로듀서가 메시징을 보내면 토픽을 구독하는 여러 컨슈머가 가져가는 방식이기때문에 in 대비 out이 1.3배 ~ 1.4배 정도된다.
- 전사 카프가 가동률 99.99%, 지난 2년간 장애 시간 60분

## 전사 카프카 운영 트러블 슈팅
### Shrinking ISR 로깅 이슈
- ISR이란?
  - In Sync Replication
  - 여러 브로커 사이 토픽, 파티션을 그루핑한 것이 ISR
  - ISR이 축소되는 것, 즉 한 브로커의 토픽, 파티션이 죽어서 올라와있는 파티션이 작아지는 것을 쉬링킹 ISR이라고한다.

브로커의 리플리케이션 구성은 리더와 팔로워로 구성되어 있다. 리더는 읽고 쓰기만 가능하다. 팔로워들은 리더를 주기적으로 동기화하는데 리더가 죽을경우 팔로워들 중 하나가 리더가 된다.

1. 카카오 카프카에서는 모든 에러로그를 로깅하고 있었다.
2. 다른 부서에서 파티션 ISR이 이상하다고 문의를 주었다.
3. 카프카 담당 부서에서는 인지하지 못했다.
4. 로그를 뒤져보니 INFO 레벨 로그로 쉬링킹 ISR이 발생하고 있었다.

결론: 쉬링킹 ISR은 INFO 레벨로 로깅되니 주의하자.

그리고 0.10.1.0 버전에서는 한 브로커가 이상동작으로 모든 노드를 이상한 노드라 생각해서 리더가 되는 버그가 있다.

### 카프카 버전 업그레이드
0.10.1.0 버그를 픽스한 버전을 올리고자 한다.
- 다운타임을 가질 수 있는 환경: 전체 브로커 종료 후 버전 업그레이드
- 다운타임을 가질 수 없는 환경: 클러스터 내 브로커 한 대씩 버전 업그레이드 실행

카카오 전사 카프카는 다운타임 없이 버전 업그레이드 진행한다.

### Rack Power
서버의 물리적인 이슈도 고려해서 IDC 각 Rack 마다 카프카를 분산 운영하는데 Rack이 모두 날라갈때를 대비해야한다.

순차적인 서버 다운에도 웬만한 경우 메시징 손실이 없지만 처음 다운된 브로커가 가장 먼저 복구되어 리더의 자격을 가지면 과거 메시징 데이터를 가지고 모든 브로커가 팔로잉하게되므로 메시징 손실이 가능하다.

### 프로듀서 ACKs 모드 이슈

프로듀서 ACKS : 파티션의 리더 브로커로 메시지를 직접 전송.

- ACKS = 0
    매우 빠르게 전송할 수 있지만, 파티션의 리더가 받았는지 알 수 없음.
    메시지 손실 위험이 높다.

- ACKS = 1
    메시지 전송도 빠른 편이고, 파티션의 리더가 받았는지 확인함
    가장 많이 사용되고, 최근 대부분의 기본값으로 사용됨.

- ACKS = ALL
    메시징 전송 속도는 가장 느리지만, 손실 없는 메시지 전송 가능.
    팔로워까지 메시지를 받았는지 확인하기 때문.

#### ACKS=1 MODE case

프로듀서가 메시지 A를 리더에게 전송 -> 리더는 저장 -> 메시지를 잘 받았다고 프로듀서에게 알려줌 -> 프로듀서와는 상관없이 팔로워와 리더사이에는 메시징 팔로잉이 일어남 -> 프로듀는 다시 B를 보내는데, 리더는 받고 ack를 보냄 -> 내부적으로 리플리케이션이 일어나는 순간 브로커 1번(리더)이 다운됨. -> 리더가 없어졌기 때문에 새로운 팔로우가 나옴. -> 프듀는 새로운 C 메시지를 새로운 리더에게 전송 -> C를 저장한 리더는 ACK를 보내고 리플리케이션을 함 -> 과거의 리더가 복구되면서 팔로워가 되는데, 잃어버린 B 메시지는 사라진다.

이런 경우는 흔하지않지만 손실이 발생할 수 있다.

### 토픽 Key 옵션
프로듀서에서 토픽 메시지를 보낼때 키라는 옵션을 사용할 수 있다.

a라는 옵션을 주면, 파티션이 2개가 있음에도 불구하고 하나의 파티션으로만 메시징을 보내게됨.

key값 없이 메시징을 보내면 그 토픽의 파티션에 균등하게 보낸다.

key 값 사용시 특정 파티션에 메시징이 몰려서 부하 분산이 안될 수 있다.


### 컨슈머 이슈
컨슈머: 파티션의 리더에게 패치 요청을 보내는 역할

컨슈머는 오프셋을 기반으로 메시지를 가져온다. 파티션이 하나인 경우 오프셋을 통해서 컨슈머의 데이터 순서가 보장되지만 여러 파티션으로 부하 분산을 의도한 경우 오프셋마다 다른 데이터가 있어서 순서가 보장되지 않는다.
메시징에 타임스템프를 추가하는 방법등을 고려해야한다.

컨슈머 그룹: 하나의 토픽을 여러 컨슈머들이 구독

컨슈머 그룹으로 그룹핑하여 컨슈머를 확장할 수 있다.
프로듀서가 토픽으로 보내는 메시지 비율을 높인다면? 컨슈머는 프로듀서의 속도를 따라가지 못한다.
그렇기때문에 컨슈머 인스턴스를 컨슈머 그룹에 추가함으로써 구독 속도를 높일 수 있다.

카프카 안에서 여러 파티션 안 데이터를 하나의 컨슈머로 보내면 부하가 있어서 컨슈머 그룹을 만들어서 컨슈머 인스턴스를 만들어 1:1로 매핑하면 안정성을 높일 수 있다.


### Burrow
LAG Checking 방법

LAG이란?

프로듀서가 보낸 메시지를 컨슈머가 얼마나 받았는지 지표

프로듀서가 10개를 보냈는데 5개를 받았다면 LAG은 5이다.

burrow는 LAG 손실을 모니터링하는 방법이다.

### 미사용 토픽 처리 방법
토픽 추가 요청만 오고 삭제 요청은 안들어온다. 그러면 미사용 토픽은 계속 쌓이게된다.

이걸 어떻게 처리해야할까!?

JMX로 토픽 상태값을 수집 저장한 후 조건에 일치하는 토픽을 삭제한다.
10일 이상 사용하지 않으면 일배치를 통해 알림을 받고 삭제한다.

## 요약
* 브로커의 로깅 옵션을 잘 고민해봐라. 인포로 떨어지는 것도있다. (예를 들면 ISR 쉬링킹)
* 서비스 영속성과 데이터 정합성 우선순위를 잘 고려해라
* 프로듀서 옵션에 대한 이해
* 컨슈머 옵션에 대한 이해
* 좋은 애플리케이션인 카프카의 적극 활용!!
